{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR for https://m.media-amazon.com/images/I/71FVeRd2jqL.jpg failed: Error processing https://m.media-amazon.com/images/I/71FVeRd2jqL.jpg: MPS backend out of memory (MPS allocated: 2.61 GB, other allocations: 5.37 GB, max allowed: 9.07 GB). Tried to allocate 1.52 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).\n",
      "OCR for https://m.media-amazon.com/images/I/71duwM3SjpL.jpg failed: Error processing https://m.media-amazon.com/images/I/71duwM3SjpL.jpg: MPS backend out of memory (MPS allocated: 2.09 GB, other allocations: 6.11 GB, max allowed: 9.07 GB). Tried to allocate 1.17 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).\n",
      "OCR for https://m.media-amazon.com/images/I/81lgxfKqUUL.jpg failed: Error processing https://m.media-amazon.com/images/I/81lgxfKqUUL.jpg: MPS backend out of memory (MPS allocated: 2.09 GB, other allocations: 6.14 GB, max allowed: 9.07 GB). Tried to allocate 1024.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).\n",
      "OCR for https://m.media-amazon.com/images/I/811VfR10yxL.jpg failed: Error processing https://m.media-amazon.com/images/I/811VfR10yxL.jpg: MPS backend out of memory (MPS allocated: 2.14 GB, other allocations: 6.54 GB, max allowed: 9.07 GB). Tried to allocate 1.05 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).\n",
      "OCR for https://m.media-amazon.com/images/I/71WLYfmMqQL.jpg failed: Error processing https://m.media-amazon.com/images/I/71WLYfmMqQL.jpg: MPS backend out of memory (MPS allocated: 2.14 GB, other allocations: 6.53 GB, max allowed: 9.07 GB). Tried to allocate 1.05 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).\n",
      "OCR for https://m.media-amazon.com/images/I/71XK5d3Oh9L.jpg failed: Error processing https://m.media-amazon.com/images/I/71XK5d3Oh9L.jpg: MPS backend out of memory (MPS allocated: 1.09 GB, other allocations: 6.55 GB, max allowed: 9.07 GB). Tried to allocate 1.56 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).\n",
      "OCR for https://m.media-amazon.com/images/I/71PDbPb275L.jpg failed: Error processing https://m.media-amazon.com/images/I/71PDbPb275L.jpg: MPS backend out of memory (MPS allocated: 1.09 GB, other allocations: 6.57 GB, max allowed: 9.07 GB). Tried to allocate 1.56 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).\n",
      "OCR for https://m.media-amazon.com/images/I/719poaEkdEL.jpg failed: Error processing https://m.media-amazon.com/images/I/719poaEkdEL.jpg: MPS backend out of memory (MPS allocated: 2.06 GB, other allocations: 6.57 GB, max allowed: 9.07 GB). Tried to allocate 992.25 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).\n",
      "Processing complete. Results saved to 'processed_results.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import easyocr\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import re\n",
    "\n",
    "# Load the CSV dataset\n",
    "csv_file_path = 'train.csv'  # Replace with the actual file path\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Initialize the EasyOCR reader\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# Unified dictionary for unit conversion including all entity types\n",
    "unit_conversion_common = {\n",
    "    # Height, width, depth units\n",
    "    r'\\bcm\\b': 'centimetre',\n",
    "    r'\\bcentimetres?\\b': 'centimetre',\n",
    "    r'\\bmm\\b': 'millimetre',\n",
    "    r'\\bmillimetres?\\b': 'millimetre',\n",
    "    r'\\bm\\b': 'metre',\n",
    "    r'\\bmetres?\\b': 'metre',\n",
    "    r'\\bin\\b': 'inch',\n",
    "    r'\\binches\\b': 'inch',\n",
    "    r'\\bft\\b': 'foot',\n",
    "    r'\\bfeet\\b': 'foot',\n",
    "    r'\\byd\\b': 'yard',\n",
    "    r'\\byards?\\b': 'yard',\n",
    "\n",
    "    # Weight and maximum weight recommendation units\n",
    "    r'\\bg\\b': 'gram',\n",
    "    r'\\bgrams?\\b': 'gram',\n",
    "    r'\\bkg\\b': 'kilogram',\n",
    "    r'\\bkilograms?\\b': 'kilogram',\n",
    "    r'\\bmicrograms?\\b': 'microgram',\n",
    "    r'\\bmg\\b': 'milligram',\n",
    "    r'\\bmilligrams?\\b': 'milligram',\n",
    "    r'\\blb\\b': 'pound',\n",
    "    r'\\blbs?\\b': 'pound',\n",
    "    r'\\bpounds?\\b': 'pound',\n",
    "    r'\\bton\\b': 'ton',\n",
    "    r'\\btons?\\b': 'ton',\n",
    "\n",
    "    # Volume units\n",
    "    r'\\bml\\b': 'millilitre',\n",
    "    r'\\bmillilitres?\\b': 'millilitre',\n",
    "    r'\\bl\\b': 'litre',\n",
    "    r'\\blitres?\\b': 'litre',\n",
    "    r'\\bcl\\b': 'centilitre',\n",
    "    r'\\bcentilitres?\\b': 'centilitre',\n",
    "    r'\\bfl oz\\b': 'fluid ounce',\n",
    "    r'\\bcup\\b': 'cup',\n",
    "    r'\\bgallon\\b': 'gallon',\n",
    "    r'\\bgallons?\\b': 'gallon',\n",
    "    r'\\bdecilitre\\b': 'decilitre',\n",
    "    r'\\bpint\\b': 'pint',\n",
    "    r'\\bquart\\b': 'quart',\n",
    "\n",
    "    # Voltage units\n",
    "    r'\\bkv\\b': 'kilovolt',\n",
    "    r'\\bkilovolts?\\b': 'kilovolt',\n",
    "    r'\\bmv\\b': 'millivolt',\n",
    "    r'\\bmillivolts?\\b': 'millivolt',\n",
    "    r'\\bv\\b': 'volt',\n",
    "    r'\\bvolts?\\b': 'volt',\n",
    "\n",
    "    # Wattage units\n",
    "    r'\\bkw\\b': 'kilowatt',\n",
    "    r'\\bkilowatts?\\b': 'kilowatt',\n",
    "    r'\\bw\\b': 'watt',\n",
    "    r'\\bwatts?\\b': 'watt'\n",
    "}\n",
    "\n",
    "# Regex patterns for different entity types\n",
    "height_width_depth_regex = r'(\\d+\\.?\\d*)\\s*(cm|centimetres?|mm|millimetres?|m|metres?|in|inches|ft|feet|yd|yards?)'\n",
    "item_weight_regex = r'(\\d+\\.?\\d*)\\s*(g|gram|grams?|kg|kilogram|kilograms?|microgram|micrograms?|mg|milligram|milligrams?|lb|lbs?|pound|pounds?|ton|tons?)'\n",
    "item_volume_regex = r'(\\d+\\.?\\d*)\\s*(ml|millilitre|millilitres?|l|litre|litres?|cl|centilitre|centilitres?|fl oz|fluid ounce|cup|gallon|gallons?|decilitre|pint|quart)'\n",
    "voltage_regex = r'(\\d+\\.?\\d*)\\s*(kv|kilovolts?|mv|millivolts?|v|volts?)'\n",
    "wattage_regex = r'(\\d+\\.?\\d*)\\s*(kw|kilowatts?|w|watts?)'\n",
    "maximum_weight_recommendation_regex = item_weight_regex  # Same regex as item_weight\n",
    "\n",
    "# Function to perform OCR on image from URL\n",
    "def ocr_from_url(image_url):\n",
    "    try:\n",
    "        # Fetch the image from the URL\n",
    "        response = requests.get(image_url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        \n",
    "        # Perform OCR and join all detected text into a single string\n",
    "        ocr_result = reader.readtext(img, detail=0)\n",
    "        return ' '.join(ocr_result)\n",
    "    except Exception as e:\n",
    "        return f\"Error processing {image_url}: {str(e)}\"\n",
    "\n",
    "# Function to extract the first occurrence of a numeric value and its unit\n",
    "def extract_first_unit_with_value(text, entity_name):\n",
    "    # Convert the entire text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Select the appropriate regex pattern based on the entity name\n",
    "    if entity_name in {'width', 'depth', 'height'}:\n",
    "        pattern = re.compile(height_width_depth_regex)\n",
    "    elif entity_name == 'item_weight':\n",
    "        pattern = re.compile(item_weight_regex)\n",
    "    elif entity_name == 'maximum_weight_recommendation':\n",
    "        pattern = re.compile(maximum_weight_recommendation_regex)\n",
    "    elif entity_name == 'voltage':\n",
    "        pattern = re.compile(voltage_regex)\n",
    "    elif entity_name == 'wattage':\n",
    "        pattern = re.compile(wattage_regex)\n",
    "    elif entity_name == 'item_volume':\n",
    "        pattern = re.compile(item_volume_regex)\n",
    "    else:\n",
    "        return ''  # Return an empty string if entity_name is not recognized\n",
    "\n",
    "    # Function to replace the unit abbreviation with the full form while keeping the numeric value\n",
    "    def replace_units(match):\n",
    "        value = float(match.group(1))  # Convert the numeric value to float\n",
    "        unit = match.group(2)  # The unit abbreviation or full name\n",
    "        for abbrev, full in unit_conversion_common.items():\n",
    "            if re.fullmatch(abbrev, unit):\n",
    "                return f\"{value} {full}\"\n",
    "        return f\"{value} {unit}\"  # Return original if no match\n",
    "\n",
    "    # Find the first occurrence\n",
    "    #Search Complexity Issue\n",
    "    match = pattern.search(text)\n",
    "    \n",
    "    # If a match is found, return the formatted numeric value and unit\n",
    "    if match:\n",
    "        return replace_units(match)\n",
    "    \n",
    "    return ''  # Return an empty string if no match is found\n",
    "\n",
    "# Limit to processing 15 images\n",
    "image_count = 100\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "# Apply OCR and regex extraction to each image URL in the dataset with specific entity names (up to 15)\n",
    "#Time complexity issue \n",
    "processed_count = 0\n",
    "for index, row in data.iterrows():\n",
    "    if processed_count >= image_count:\n",
    "        break  # Stop after processing 15 images\n",
    "    \n",
    "    entity_name = row['entity_name'].strip().lower()\n",
    "    if entity_name in ['width', 'height', 'depth', 'item_weight', 'maximum_weight_recommendation', 'voltage', 'wattage', 'item_volume']:\n",
    "        image_url = row['image_link']\n",
    "        group_id = row['group_id']\n",
    "        \n",
    "        ocr_text = ocr_from_url(image_url)\n",
    "        \n",
    "        if \"Error\" not in ocr_text:\n",
    "            # Extract the first occurrence of a unit and its numeric value\n",
    "            extracted_text = extract_first_unit_with_value(ocr_text, entity_name)\n",
    "            results.append({\n",
    "                'image_url': image_url,\n",
    "                'group_id': group_id,\n",
    "                'extracted_text': extracted_text\n",
    "            })\n",
    "            processed_count += 1  # Increment the processed count\n",
    "        else:\n",
    "            print(f\"OCR for {image_url} failed: {ocr_text}\")\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Rename 'extracted_text' column to 'entity_value'\n",
    "results_df.rename(columns={'extracted_text': 'entity_value'}, inplace=True)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "results_df.to_csv('processed_results.csv', index=False)\n",
    "\n",
    "print(\"Processing complete. Results saved to 'processed_results.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
